{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Parameter Study Tutorial\n",
    "\n",
    "This tutorial demonstrates how to run the Weight Parameter Study experiment, which investigates how the learning rate parameter (w) affects agent learning dynamics, convergence speed, and system performance.\n",
    "\n",
    "## Concept\n",
    "The weight parameter controls how quickly agents update their probability distributions based on environmental feedback. Higher weights lead to faster learning but may reduce exploration, whilst lower weights maintain exploration but converge more slowly.\n",
    "\n",
    "This experiment tests the fundamental exploration-exploitation trade-off in multi-agent learning systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path to import the experiment modules\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "\n",
    "from experiments.weight_parameter_study import WeightParameterStudy, run_weight_parameter_study\n",
    "from utils.config import Config\n",
    "from evaluation.metrics import calculate_entropy, calculate_convergence_speed\n",
    "from visualisation.plots import plot_parameter_sensitivity, plot_convergence_comparison\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concept Explanation\n",
    "\n",
    "### What is the Weight Parameter?\n",
    "The weight parameter (w) controls the learning intensity in the stochastic learning algorithm. It determines how much agents update their probability distributions based on cost feedback.\n",
    "\n",
    "**Learning Update Rule:**\n",
    "p_{i,r}(t+1) = (1-λ_i(t)) * p_{i,r}(t) + λ_i(t) * δ_{r,a_i(t)}\")\n",
    ",where λ_i(t) = w * L_{a_i(t)}(t)\n",
    "\n",
    "- **Higher w** = Faster learning = Less exploration\n",
    "- **Lower w** = Slower learning = More exploration\n",
    "\n",
    "**Study weight parameter effects** \\\n",
    "     - Understanding the exploration-exploitation trade-off \\\n",
    "     - Finding optimal learning rates for different scenarios \\\n",
    "     - Balancing convergence speed with solution quality \\\n",
    "     - Identifying parameter ranges for practical deployment \n",
    "\n",
    "**Key research questions** \\\n",
    "     - How does w affect convergence speed? \\\n",
    "     - What is the relationship between w and final system cost? \\\n",
    "     - How does w influence learning stability? \\\n",
    "     - What is the optimal w range for different applications? \\\n",
    "     - How does *w* balance exploration vs exploitation? \n",
    "     \n",
    "**Expected Outcomes** \\\n",
    "     - Higher weights should lead to faster convergence \\\n",
    "     - Lower weights should maintain better exploration \\\n",
    "     - There should be an optimal range balancing speed and quality \\\n",
    "     - Very high weights may lead to instability \\\n",
    "     - Very low weights may be too slow for practical use \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameter Configuration\n",
    "\n",
    "In this section, we'll configure the experiment parameters. You can modify these values to explore different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters\n",
    "num_agents = 10\n",
    "num_resources = 5\n",
    "num_iterations = 1000\n",
    "num_replications = 30\n",
    "\n",
    "# Weight parameter configuration\n",
    "weight_values = [0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "# Resource capacity configuration (balanced)\n",
    "relative_capacity = [1.0/num_resources] * num_resources\n",
    "\n",
    "# Convergence parameters\n",
    "convergence_threshold_entropy = 0.1\n",
    "convergence_threshold_max_prob = 0.9\n",
    "\n",
    "# Output configuration\n",
    "output_dir = \"results/weight_parameter_tutorial\"\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 80)\n",
    "print(\"EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Number of agents: {num_agents}\")\n",
    "print(f\"Number of resources: {num_resources}\")\n",
    "print(f\"Number of iterations: {num_iterations}\")\n",
    "print(f\"Number of replications: {num_replications}\")\n",
    "print(f\"Weight values: {weight_values}\")\n",
    "print(f\"Relative capacity: {[f'{c:.3f}' for c in relative_capacity]}\")\n",
    "print(f\"Convergence entropy threshold: {convergence_threshold_entropy}\")\n",
    "print(f\"Convergence max probability threshold: {convergence_threshold_max_prob}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running the Experiment\n",
    "\n",
    "Now we'll create and run the Weight Parameter Study experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_weight_parameter_experiment(params):\n",
    "    \"\"\"\n",
    "    Run the weight parameter study experiment with the given parameters.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"RUNNING WEIGHT PARAMETER STUDY EXPERIMENT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_path = Path(params['output_dir'])\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create custom configuration\n",
    "    config = Config()\n",
    "    config.num_agents = params['num_agents']\n",
    "    config.num_resources = params['num_resources']\n",
    "    config.relative_capacity = params['relative_capacity']\n",
    "    config.num_iterations = params['num_iterations']\n",
    "    config.agent_initialisation_method = \"uniform\"\n",
    "    \n",
    "    # Create and run the experiment\n",
    "    print(f\"Creating WeightParameterStudy with {len(params['weight_values'])} weight values...\")\n",
    "    study = WeightParameterStudy(\n",
    "        weight_values=params['weight_values'],\n",
    "        results_dir=params['output_dir'],\n",
    "        experiment_name=\"weight_parameter_tutorial\"\n",
    "    )\n",
    "    \n",
    "    # Override base config with user parameters\n",
    "    study.base_config = config\n",
    "    \n",
    "    print(f\"Running experiment with {params['num_replications']} replications per weight value...\")\n",
    "    print(\"This may take several minutes depending on the number of replications...\")\n",
    "    \n",
    "    # Run experiment\n",
    "    full_results = study.run_experiment(num_episodes=params['num_replications'])\n",
    "    \n",
    "    # Convert results to expected format\n",
    "    study.results = []\n",
    "    for config_result in full_results['results']:\n",
    "        config_params = config_result['config_params']\n",
    "        for episode_result in config_result['episode_results']:\n",
    "            study.results.append({\n",
    "                'config_params': config_params,\n",
    "                'simulation_results': episode_result,\n",
    "                'replication_id': episode_result['episode']\n",
    "            })\n",
    "    \n",
    "    \n",
    "    return study\n",
    "\n",
    "# Create parameter dictionary\n",
    "params = {\n",
    "    'num_agents': num_agents,\n",
    "    'num_resources': num_resources,\n",
    "    'num_iterations': num_iterations,\n",
    "    'num_replications': num_replications,\n",
    "    'weight_values': weight_values,\n",
    "    'relative_capacity': relative_capacity,\n",
    "    'convergence_threshold_entropy': convergence_threshold_entropy,\n",
    "    'convergence_threshold_max_prob': convergence_threshold_max_prob,\n",
    "    'output_dir': output_dir\n",
    "}\n",
    "\n",
    "# Run the experiment\n",
    "study = run_weight_parameter_experiment(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generating Analysis and Plots\n",
    "\n",
    "Now we'll generate comprehensive analysis and create visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_and_plots(study, params):\n",
    "    \"\"\"\n",
    "    Generate comprehensive analysis and create all figures.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"GENERATING ANALYSIS AND PLOTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Generate detailed analysis\n",
    "    print(\"Generating detailed statistical analysis...\")\n",
    "    analysis_results = study.generate_detailed_analysis()\n",
    "    \n",
    "    # Create comprehensive plots\n",
    "    print(\"Creating comprehensive visualisations...\")\n",
    "    plots_dir = f\"{params['output_dir']}/plots\"\n",
    "    plot_files = study.create_comprehensive_plots(plots_dir)\n",
    "    \n",
    "    print(f\"Generated {len(plot_files)} plot files:\")\n",
    "    for plot_file in plot_files:\n",
    "        print(f\"  - {plot_file}\")\n",
    "    \n",
    "    # Save results\n",
    "    print(\"Saving results and analysis...\")\n",
    "    study.save_results(params['output_dir'])\n",
    "    \n",
    "    # Generate comprehensive report\n",
    "    print(\"Generating comprehensive analysis report...\")\n",
    "    report = study.generate_comprehensive_report()\n",
    "    \n",
    "    # Save report\n",
    "    report_path = f\"{params['output_dir']}/comprehensive_analysis_report.txt\"\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"Analysis report saved to: {report_path}\")\n",
    "    \n",
    "    # Display key findings\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KEY FINDINGS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if 'recommendations' in analysis_results:\n",
    "        recs = analysis_results['recommendations']\n",
    "        print(f\"Optimal weight for cost performance: {recs.get('optimal_for_cost', 'N/A')}\")\n",
    "        print(f\"Optimal weight for convergence speed: {recs.get('optimal_for_convergence', 'N/A')}\")\n",
    "        print(f\"Recommended weight range: {recs.get('suggested_range', 'N/A')}\")\n",
    "        print(f\"Cost sensitivity: {recs.get('cost_sensitivity', 'N/A')}\")\n",
    "    \n",
    "    if 'hypothesis_evaluation' in analysis_results:\n",
    "        print(\"\\nHypothesis Evaluation:\")\n",
    "        hyp_eval = analysis_results['hypothesis_evaluation']\n",
    "        for key, value in hyp_eval.items():\n",
    "            status = \"✓\" if value else \"✗\"\n",
    "            formatted_key = key.replace('_', ' ').title()\n",
    "            print(f\"  {status} {formatted_key}: {value}\")\n",
    "    \n",
    "    return analysis_results, plot_files\n",
    "\n",
    "# Generate analysis and plots\n",
    "analysis_results, plot_files = generate_analysis_and_plots(study, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Displaying Generated Plots\n",
    "\n",
    "Let's display the key plots inline to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key plots inline\n",
    "plots_dir = f\"{params['output_dir']}/plots\"\n",
    "\n",
    "# List of key plots to display\n",
    "key_plots = [\n",
    "    'convergence_times_vs_weight.png',\n",
    "    'costs_vs_weight.png',\n",
    "    'performance_heatmap.png',\n",
    "    'cost_convergence_tradeoff.png',\n",
    "    'system_behaviour_radar.png'\n",
    "]\n",
    "\n",
    "print(\"Displaying key plots:\")\n",
    "for plot_name in key_plots:\n",
    "    plot_path = f\"{plots_dir}/{plot_name}\"\n",
    "    if os.path.exists(plot_path):\n",
    "        print(f\"\\n{plot_name}:\")\n",
    "        img = plt.imread(plot_path)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"\\n{plot_name} not found at {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Output Structure\n",
    "\n",
    "Here's what was generated and where to find it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " output_path = Path(params['output_dir'])\n",
    "    \n",
    "All results are saved in: {output_path} \\\n",
    "    File structure: \\\n",
    "        {output_path}/\" \\\n",
    "            ├── plots/\") \\\n",
    "            │   ├── convergence_times_vs_weight.png\") \\\n",
    "            │   ├── final_entropy_vs_weight.png\") \\\n",
    "            │   ├── costs_vs_weight.png\") \\\n",
    "            │   ├── performance_heatmap.png\") \\\n",
    "            │   ├── system_behaviour_radar.png\") \\\n",
    "            │   ├── comparative_behaviour_radar.png\") \\\n",
    "            │   ├── cost_evolution_comparison.png\") \\\n",
    "            │   ├── cost_convergence_tradeoff.png\") \\\n",
    "            │   ├── stability_performance_tradeoff.png\") \\\n",
    "            │   ├── weight_comparison_overview.png\") \\\n",
    "            │   └── performance_distributions.png\") \\\n",
    "            ├── weight_study_raw_data.csv\") \\\n",
    "            ├── weight_study_analysis.json\") \\\n",
    "            └── comprehensive_analysis_report.txt\")\n",
    "\n",
    "**File descriptions:** \\\n",
    "plots/: All generated visualisations \\\n",
    "weight_study_raw_data.csv: Raw experimental data \\\n",
    "weight_study_analysis.json: Statistical analysis results \\\n",
    "comprehensive_analysis_report.txt: Detailed analysis report\n",
    "\n",
    "**Key plots explained:** \\\n",
    "convergence_times_vs_weight.png: How weight affects convergence speed \\\n",
    "costs_vs_weight.png: How weight affects final system cost \\\n",
    "performance_heatmap.png: Normalised performance across all metrics \\\n",
    "system_behaviour_radar.png: Multi-dimensional system behaviour patterns \\\n",
    "cost_convergence_tradeoff.png: Trade-off between cost and convergence speed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tutorial Summary\n",
    "\n",
    "This tutorial has successfully demonstrated the Weight Parameter Study experiment. Here's what we accomplished:\n",
    "\n",
    "### Key Findings:\n",
    "- **Convergence Speed**: Higher weights (0.7-0.9) achieve significantly faster convergence\n",
    "- **System Performance**: Weight = 0.9 typically provides optimal cost performance\n",
    "- **Learning Stability**: Moderate weights (0.3-0.5) show better stability\n",
    "- **Optimal Range**: Recommended range 0.7-0.9 for most applications\n",
    "\n",
    "### What You Can Do Next:\n",
    "- Examine the generated plots in the plots/ directory\n",
    "- Review the analysis report for detailed findings\n",
    "- Modify parameters and run again to explore different scenarios\n",
    "- Use the raw data for further custom analysis\n",
    "- Compare results with other experiments to understand system dynamics\n",
    "\n",
    "### Expected Results:\n",
    "The experiment typically shows:\n",
    "1. **Convergence Speed**: Higher weights (0.7-0.9) achieve significantly faster convergence\n",
    "2. **System Performance**: Weight = 0.9 typically provides optimal cost performance\n",
    "3. **Learning Stability**: Moderate weights (0.3-0.5) show better stability\n",
    "4. **Optimal Range**: Recommended range 0.7-0.9 for most applications\n",
    "\n",
    "All results have been saved to the specified output directory for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
